{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-10T04:15:06.132069Z",
     "iopub.status.busy": "2023-04-10T04:15:06.131156Z",
     "iopub.status.idle": "2023-04-10T04:15:22.911266Z",
     "shell.execute_reply": "2023-04-10T04:15:22.910021Z",
     "shell.execute_reply.started": "2023-04-10T04:15:06.132015Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:15:22.914302Z",
     "iopub.status.busy": "2023-04-10T04:15:22.913890Z",
     "iopub.status.idle": "2023-04-10T04:15:25.013662Z",
     "shell.execute_reply": "2023-04-10T04:15:25.012299Z",
     "shell.execute_reply.started": "2023-04-10T04:15:22.914256Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/datasetuno/cable/* /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:15:25.015747Z",
     "iopub.status.busy": "2023-04-10T04:15:25.015362Z",
     "iopub.status.idle": "2023-04-10T04:15:25.351584Z",
     "shell.execute_reply": "2023-04-10T04:15:25.350593Z",
     "shell.execute_reply.started": "2023-04-10T04:15:25.015697Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uuid, os\n",
    "\n",
    "ACCESS_KEY = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "SECRET_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "BUCKET_NAME = os.environ.get('BUCKET_NAME')\n",
    "\n",
    "DATASET_NAME = \"cable\"\n",
    "GENERATOR_NAME = \"generator_weights.pt\"\n",
    "GENERATOR_PATH = f\"{DATASET_NAME}/{GENERATOR_NAME}\"\n",
    "DESCRIMINATOR_NAME = \"descriminator_weights.pt\"\n",
    "DESCRIMINATOR_PATH = f\"{DATASET_NAME}/{DESCRIMINATOR_NAME}\"\n",
    "IMAGES_NAME = \"images.zip\"\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=ACCESS_KEY, \n",
    "    aws_secret_access_key=SECRET_KEY\n",
    ")\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNLOADING THE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:15:25.354308Z",
     "iopub.status.busy": "2023-04-10T04:15:25.353949Z",
     "iopub.status.idle": "2023-04-10T04:15:26.530499Z",
     "shell.execute_reply": "2023-04-10T04:15:26.529342Z",
     "shell.execute_reply.started": "2023-04-10T04:15:25.354270Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket.download_file(Key=GENERATOR_PATH, Filename=GENERATOR_NAME)\n",
    "except:\n",
    "    print(\"The generator weights don't exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNLOADING THE DESCRIMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:15:26.531892Z",
     "iopub.status.busy": "2023-04-10T04:15:26.531618Z",
     "iopub.status.idle": "2023-04-10T04:15:26.537791Z",
     "shell.execute_reply": "2023-04-10T04:15:26.536751Z",
     "shell.execute_reply.started": "2023-04-10T04:15:26.531863Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket.download_file(Bucket=BUCKET_NAME, Key=DESCRIMINATOR_PATH, Filename=DESCRIMINATOR_NAME)\n",
    "except:\n",
    "    print(\"The descriminator weights don't exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T23:45:14.501973Z",
     "iopub.status.busy": "2023-04-09T23:45:14.501355Z",
     "iopub.status.idle": "2023-04-09T23:45:15.440085Z",
     "shell.execute_reply": "2023-04-09T23:45:15.438634Z",
     "shell.execute_reply.started": "2023-04-09T23:45:14.501935Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf images/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:46:05.059331Z",
     "iopub.status.busy": "2023-04-10T04:46:05.058134Z",
     "iopub.status.idle": "2023-04-10T04:46:06.000295Z",
     "shell.execute_reply": "2023-04-10T04:46:05.998941Z",
     "shell.execute_reply.started": "2023-04-10T04:46:05.059269Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf infogan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:46:06.004289Z",
     "iopub.status.busy": "2023-04-10T04:46:06.003911Z",
     "iopub.status.idle": "2023-04-10T04:46:08.347254Z",
     "shell.execute_reply": "2023-04-10T04:46:08.346046Z",
     "shell.execute_reply.started": "2023-04-10T04:46:06.004254Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://transfer.sh/pDHg1t/infogan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:40:14.829173Z",
     "iopub.status.busy": "2023-04-10T04:40:14.828032Z",
     "iopub.status.idle": "2023-04-10T04:40:18.745659Z",
     "shell.execute_reply": "2023-04-10T04:40:18.744350Z",
     "shell.execute_reply.started": "2023-04-10T04:40:14.829116Z"
    }
   },
   "outputs": [],
   "source": [
    "!python dcgan.py --n_epochs 5000 --batch_size 64 --lr 0.0002 --b1 0.5 --b2 0.999 --n_cpu 8 --latent_dim 100 --img_size 128 --channels 3 --sample_interval 50 --save_weights True --augment_data True --load_weights True --save_path \"augment\" --count 100 --weights_filename \"weights.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload or Overwrite the Generator weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket.upload_file(Key=GENERATOR_PATH, Filename=GENERATOR_NAME)\n",
    "    print(f'File {GENERATOR_NAME} uploaded to S3 bucket {BUCKET_NAME}')\n",
    "except Exception as e:\n",
    "    print(f\"Something went wrong: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload or Overwrite the Descriminator weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket.upload_file(Key=DESCRIMINATOR_PATH, Filename=DESCRIMINATOR_NAME)\n",
    "    print(f'File {DESCRIMINATOR_NAME} uploaded to S3 bucket {BUCKET_NAME}')\n",
    "except:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip images.zip images/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload or Overwrite the Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = f\"{DATASET_NAME}/images-{uuid.uuid4()}.zip\"\n",
    "try:\n",
    "    bucket.upload_file(Key=IMAGES_PATH, Filename=IMAGES_NAME)\n",
    "    print(f'File {IMAGES_NAME} uploaded to S3 bucket {BUCKET_NAME}')\n",
    "except:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T04:35:51.486315Z",
     "iopub.status.busy": "2023-04-10T04:35:51.485876Z",
     "iopub.status.idle": "2023-04-10T04:35:52.685340Z",
     "shell.execute_reply": "2023-04-10T04:35:52.684046Z",
     "shell.execute_reply.started": "2023-04-10T04:35:51.486273Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "os.makedirs(\"images/static/\", exist_ok=True)\n",
    "os.makedirs(\"images/varying_c1/\", exist_ok=True)\n",
    "os.makedirs(\"images/varying_c2/\", exist_ok=True)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=62, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--code_dim\", type=int, default=2, help=\"latent code\")\n",
    "parser.add_argument(\"--n_classes\", type=int, default=10, help=\"number of classes for dataset\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def to_categorical(y, num_columns):\n",
    "    \"\"\"Returns one-hot encoded Variable\"\"\"\n",
    "    y_cat = np.zeros((y.shape[0], num_columns))\n",
    "    y_cat[range(y.shape[0]), y] = 1.0\n",
    "\n",
    "    return Variable(FloatTensor(y_cat))\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        input_dim = opt.latent_dim + opt.n_classes + opt.code_dim\n",
    "\n",
    "        self.init_size = opt.img_size // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(input_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels, code):\n",
    "        gen_input = torch.cat((noise, labels, code), -1)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.n_classes), nn.Softmax())\n",
    "        self.latent_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.code_dim))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "        latent_code = self.latent_layer(out)\n",
    "\n",
    "        return validity, label, latent_code\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "categorical_loss = torch.nn.CrossEntropyLoss()\n",
    "continuous_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Loss weights\n",
    "lambda_cat = 1\n",
    "lambda_con = 0.1\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    categorical_loss.cuda()\n",
    "    continuous_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs(\"data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_info = torch.optim.Adam(\n",
    "    itertools.chain(generator.parameters(), discriminator.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2)\n",
    ")\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "# Static generator inputs for sampling\n",
    "static_z = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.latent_dim))))\n",
    "static_label = to_categorical(\n",
    "    np.array([num for _ in range(opt.n_classes) for num in range(opt.n_classes)]), num_columns=opt.n_classes\n",
    ")\n",
    "static_code = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.code_dim))))\n",
    "\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Static sample\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    static_sample = generator(z, static_label, static_code)\n",
    "    save_image(static_sample.data, \"images/static/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "    # Get varied c1 and c2\n",
    "    zeros = np.zeros((n_row ** 2, 1))\n",
    "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
    "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
    "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
    "    sample1 = generator(static_z, static_label, c1)\n",
    "    sample2 = generator(static_z, static_label, c2)\n",
    "    save_image(sample1.data, \"images/varying_c1/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "    save_image(sample2.data, \"images/varying_c2/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = to_categorical(labels.numpy(), num_columns=opt.n_classes)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        label_input = to_categorical(np.random.randint(0, opt.n_classes, batch_size), num_columns=opt.n_classes)\n",
    "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, label_input, code_input)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity, _, _ = discriminator(gen_imgs)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        real_pred, _, _ = discriminator(real_imgs)\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ------------------\n",
    "        # Information Loss\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_info.zero_grad()\n",
    "\n",
    "        # Sample labels\n",
    "        sampled_labels = np.random.randint(0, opt.n_classes, batch_size)\n",
    "\n",
    "        # Ground truth labels\n",
    "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n",
    "\n",
    "        # Sample noise, labels and code as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        label_input = to_categorical(sampled_labels, num_columns=opt.n_classes)\n",
    "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
    "\n",
    "        gen_imgs = generator(z, label_input, code_input)\n",
    "        _, pred_label, pred_code = discriminator(gen_imgs)\n",
    "\n",
    "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + lambda_con * continuous_loss(\n",
    "            pred_code, code_input\n",
    "        )\n",
    "\n",
    "        info_loss.backward()\n",
    "        optimizer_info.step()\n",
    "\n",
    "        # --------------\n",
    "        # Log Progress\n",
    "        # --------------\n",
    "\n",
    "        print(\n",
    "            \"[infogan][Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), info_loss.item())\n",
    "        )\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)\n",
    "\n",
    "later = datetime.now()\n",
    "print((later - now).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
