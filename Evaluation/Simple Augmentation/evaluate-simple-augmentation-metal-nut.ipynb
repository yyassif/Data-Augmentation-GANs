{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.utils.data as data\nfrom PIL import Image\nfrom scipy.stats import ttest_ind\nfrom sklearn.metrics import roc_auc_score\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-16T11:24:53.556162Z","iopub.execute_input":"2023-06-16T11:24:53.556523Z","iopub.status.idle":"2023-06-16T11:24:55.628494Z","shell.execute_reply.started":"2023-06-16T11:24:53.556454Z","shell.execute_reply":"2023-06-16T11:24:55.627527Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/metal-nut/* /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:24:55.635999Z","iopub.execute_input":"2023-06-16T11:24:55.636346Z","iopub.status.idle":"2023-06-16T11:24:57.803517Z","shell.execute_reply.started":"2023-06-16T11:24:55.636313Z","shell.execute_reply":"2023-06-16T11:24:57.802257Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_dir = 'metal_nut'\ntrain_dir = os.path.join(data_dir,'train')\ntest_dir = os.path.join(data_dir,'test')","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:24:57.805521Z","iopub.execute_input":"2023-06-16T11:24:57.805907Z","iopub.status.idle":"2023-06-16T11:24:57.812254Z","shell.execute_reply.started":"2023-06-16T11:24:57.805869Z","shell.execute_reply":"2023-06-16T11:24:57.811228Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(data.Dataset):\n    def __init__(self, data_dir, transform=None):\n        super(ImageDataset, self).__init__()\n        self.data_dir = data_dir\n        self.transform = transform\n        self.data = []\n        self.targets = []\n\n        # Iterate over the data directory and load images\n        for root, dirs, files in os.walk(data_dir):\n            for file in files:\n                image_path = os.path.join(root, file)\n                image = Image.open(image_path)\n                self.data.append(image)\n\n                # Determine the class label based on the directory name\n                class_label = os.path.basename(root)\n                if class_label == \"good\":\n                    self.targets.append(1)  # Assign class 1 for \"good\"\n                elif class_label == \"bad\":\n                    self.targets.append(0)  # Assign class 0 for \"bad\"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = self.data[index]\n        target = self.targets[index]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, target","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:24:57.815944Z","iopub.execute_input":"2023-06-16T11:24:57.816645Z","iopub.status.idle":"2023-06-16T11:24:57.826507Z","shell.execute_reply.started":"2023-06-16T11:24:57.816614Z","shell.execute_reply":"2023-06-16T11:24:57.825500Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Flatten(),\n            nn.Linear(32 * 16 * 16, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:24:57.827785Z","iopub.execute_input":"2023-06-16T11:24:57.828248Z","iopub.status.idle":"2023-06-16T11:24:57.839957Z","shell.execute_reply.started":"2023-06-16T11:24:57.828216Z","shell.execute_reply":"2023-06-16T11:24:57.838976Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomRotation(50),  # Rotate randomly between -50 and 50 degrees\n    transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),  # Random scale and crop to 256x256\n    transforms.RandomHorizontalFlip(),  # Flip horizontally with a 50% chance\n    transforms.ToTensor(),\n])\n\n# Create data loaders\ntrain_dataset = ImageDataset(train_dir, transform=transform)\ntest_dataset = ImageDataset(test_dir, transform=transform)\n\n# Define data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Set device for training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Instantiate the CNN model\nmodel = CNN().to(device)\n\n\n# Define loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = Adam(model.parameters(), lr=0.002)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:24:57.841629Z","iopub.execute_input":"2023-06-16T11:24:57.841959Z","iopub.status.idle":"2023-06-16T11:25:00.822136Z","shell.execute_reply.started":"2023-06-16T11:24:57.841929Z","shell.execute_reply":"2023-06-16T11:25:00.821071Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 100\nmodel.train()\n\nfor epoch in range(num_epochs):\n    for images, targets in train_loader:\n        # Move data to device\n        images = images.to(device)\n        targets = targets.unsqueeze(1).to(device)\n        \n        # Convert targets to float\n        targets = targets.float()\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Print training loss\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:25:00.823884Z","iopub.execute_input":"2023-06-16T11:25:00.824267Z","iopub.status.idle":"2023-06-16T11:26:44.741775Z","shell.execute_reply.started":"2023-06-16T11:25:00.824233Z","shell.execute_reply":"2023-06-16T11:26:44.740713Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch [1/100], Loss: 0.6775\nEpoch [1/100], Loss: 0.3057\nEpoch [1/100], Loss: 1.2572\nEpoch [1/100], Loss: 0.0283\nEpoch [1/100], Loss: 0.1961\nEpoch [1/100], Loss: 0.3781\nEpoch [1/100], Loss: 0.1855\nEpoch [1/100], Loss: 0.1224\nEpoch [2/100], Loss: 0.6459\nEpoch [2/100], Loss: 0.1437\nEpoch [2/100], Loss: 0.1424\nEpoch [2/100], Loss: 0.0434\nEpoch [2/100], Loss: 0.0325\nEpoch [2/100], Loss: 0.1429\nEpoch [2/100], Loss: 0.0117\nEpoch [2/100], Loss: 0.8382\nEpoch [3/100], Loss: 0.0199\nEpoch [3/100], Loss: 0.1427\nEpoch [3/100], Loss: 0.5776\nEpoch [3/100], Loss: 0.1232\nEpoch [3/100], Loss: 0.2182\nEpoch [3/100], Loss: 0.2791\nEpoch [3/100], Loss: 0.1627\nEpoch [3/100], Loss: 0.1160\nEpoch [4/100], Loss: 0.1544\nEpoch [4/100], Loss: 0.0350\nEpoch [4/100], Loss: 0.2823\nEpoch [4/100], Loss: 0.1671\nEpoch [4/100], Loss: 0.1738\nEpoch [4/100], Loss: 0.5140\nEpoch [4/100], Loss: 0.1554\nEpoch [4/100], Loss: 0.7056\nEpoch [5/100], Loss: 0.0571\nEpoch [5/100], Loss: 0.3116\nEpoch [5/100], Loss: 0.2122\nEpoch [5/100], Loss: 0.2341\nEpoch [5/100], Loss: 0.2443\nEpoch [5/100], Loss: 0.3333\nEpoch [5/100], Loss: 0.2121\nEpoch [5/100], Loss: 0.1175\nEpoch [6/100], Loss: 0.1572\nEpoch [6/100], Loss: 0.3362\nEpoch [6/100], Loss: 0.2498\nEpoch [6/100], Loss: 0.2592\nEpoch [6/100], Loss: 0.1407\nEpoch [6/100], Loss: 0.0191\nEpoch [6/100], Loss: 0.0177\nEpoch [6/100], Loss: 0.7006\nEpoch [7/100], Loss: 0.2551\nEpoch [7/100], Loss: 0.0396\nEpoch [7/100], Loss: 0.2363\nEpoch [7/100], Loss: 0.1515\nEpoch [7/100], Loss: 0.1572\nEpoch [7/100], Loss: 0.1613\nEpoch [7/100], Loss: 0.3101\nEpoch [7/100], Loss: 0.0841\nEpoch [8/100], Loss: 0.1551\nEpoch [8/100], Loss: 0.0623\nEpoch [8/100], Loss: 0.4338\nEpoch [8/100], Loss: 0.0401\nEpoch [8/100], Loss: 0.1355\nEpoch [8/100], Loss: 0.0283\nEpoch [8/100], Loss: 0.3793\nEpoch [8/100], Loss: 0.6530\nEpoch [9/100], Loss: 0.0362\nEpoch [9/100], Loss: 0.2343\nEpoch [9/100], Loss: 0.3197\nEpoch [9/100], Loss: 0.1581\nEpoch [9/100], Loss: 0.2396\nEpoch [9/100], Loss: 0.1041\nEpoch [9/100], Loss: 0.2408\nEpoch [9/100], Loss: 0.0929\nEpoch [10/100], Loss: 0.2338\nEpoch [10/100], Loss: 0.1499\nEpoch [10/100], Loss: 0.2346\nEpoch [10/100], Loss: 0.1416\nEpoch [10/100], Loss: 0.3508\nEpoch [10/100], Loss: 0.1379\nEpoch [10/100], Loss: 0.0302\nEpoch [10/100], Loss: 0.0275\nEpoch [11/100], Loss: 0.1420\nEpoch [11/100], Loss: 0.3914\nEpoch [11/100], Loss: 0.0201\nEpoch [11/100], Loss: 0.1434\nEpoch [11/100], Loss: 0.2580\nEpoch [11/100], Loss: 0.2498\nEpoch [11/100], Loss: 0.1386\nEpoch [11/100], Loss: 0.0435\nEpoch [12/100], Loss: 0.3326\nEpoch [12/100], Loss: 0.1435\nEpoch [12/100], Loss: 0.0600\nEpoch [12/100], Loss: 0.0599\nEpoch [12/100], Loss: 0.1438\nEpoch [12/100], Loss: 0.3327\nEpoch [12/100], Loss: 0.2367\nEpoch [12/100], Loss: 0.0460\nEpoch [13/100], Loss: 0.1395\nEpoch [13/100], Loss: 0.0377\nEpoch [13/100], Loss: 0.0317\nEpoch [13/100], Loss: 0.1393\nEpoch [13/100], Loss: 0.1427\nEpoch [13/100], Loss: 0.4075\nEpoch [13/100], Loss: 0.5134\nEpoch [13/100], Loss: 0.0283\nEpoch [14/100], Loss: 0.1392\nEpoch [14/100], Loss: 0.2354\nEpoch [14/100], Loss: 0.0610\nEpoch [14/100], Loss: 0.1488\nEpoch [14/100], Loss: 0.2342\nEpoch [14/100], Loss: 0.2333\nEpoch [14/100], Loss: 0.2340\nEpoch [14/100], Loss: 0.0701\nEpoch [15/100], Loss: 0.1485\nEpoch [15/100], Loss: 0.0555\nEpoch [15/100], Loss: 0.3368\nEpoch [15/100], Loss: 0.0380\nEpoch [15/100], Loss: 0.2473\nEpoch [15/100], Loss: 0.2504\nEpoch [15/100], Loss: 0.1370\nEpoch [15/100], Loss: 0.6207\nEpoch [16/100], Loss: 0.0414\nEpoch [16/100], Loss: 0.1428\nEpoch [16/100], Loss: 0.1458\nEpoch [16/100], Loss: 0.2331\nEpoch [16/100], Loss: 0.3152\nEpoch [16/100], Loss: 0.2340\nEpoch [16/100], Loss: 0.1572\nEpoch [16/100], Loss: 0.0788\nEpoch [17/100], Loss: 0.2340\nEpoch [17/100], Loss: 0.0669\nEpoch [17/100], Loss: 0.2344\nEpoch [17/100], Loss: 0.1417\nEpoch [17/100], Loss: 0.3432\nEpoch [17/100], Loss: 0.2425\nEpoch [17/100], Loss: 0.0378\nEpoch [17/100], Loss: 0.0350\nEpoch [18/100], Loss: 0.1384\nEpoch [18/100], Loss: 0.2500\nEpoch [18/100], Loss: 0.0268\nEpoch [18/100], Loss: 0.3686\nEpoch [18/100], Loss: 0.1389\nEpoch [18/100], Loss: 0.1383\nEpoch [18/100], Loss: 0.1394\nEpoch [18/100], Loss: 0.5916\nEpoch [19/100], Loss: 0.2358\nEpoch [19/100], Loss: 0.2341\nEpoch [19/100], Loss: 0.1604\nEpoch [19/100], Loss: 0.2393\nEpoch [19/100], Loss: 0.1743\nEpoch [19/100], Loss: 0.1747\nEpoch [19/100], Loss: 0.1704\nEpoch [19/100], Loss: 0.0890\nEpoch [20/100], Loss: 0.3139\nEpoch [20/100], Loss: 0.2335\nEpoch [20/100], Loss: 0.2328\nEpoch [20/100], Loss: 0.0474\nEpoch [20/100], Loss: 0.1396\nEpoch [20/100], Loss: 0.1390\nEpoch [20/100], Loss: 0.1393\nEpoch [20/100], Loss: 0.0211\nEpoch [21/100], Loss: 0.2699\nEpoch [21/100], Loss: 0.0159\nEpoch [21/100], Loss: 0.1476\nEpoch [21/100], Loss: 0.1476\nEpoch [21/100], Loss: 0.1467\nEpoch [21/100], Loss: 0.4078\nEpoch [21/100], Loss: 0.1420\nEpoch [21/100], Loss: 0.6250\nEpoch [22/100], Loss: 0.0436\nEpoch [22/100], Loss: 0.0605\nEpoch [22/100], Loss: 0.3142\nEpoch [22/100], Loss: 0.2363\nEpoch [22/100], Loss: 0.1695\nEpoch [22/100], Loss: 0.2425\nEpoch [22/100], Loss: 0.1069\nEpoch [22/100], Loss: 0.8494\nEpoch [23/100], Loss: 0.1802\nEpoch [23/100], Loss: 0.3129\nEpoch [23/100], Loss: 0.1885\nEpoch [23/100], Loss: 0.1234\nEpoch [23/100], Loss: 0.1782\nEpoch [23/100], Loss: 0.2394\nEpoch [23/100], Loss: 0.2353\nEpoch [23/100], Loss: 0.0683\nEpoch [24/100], Loss: 0.1433\nEpoch [24/100], Loss: 0.2394\nEpoch [24/100], Loss: 0.1382\nEpoch [24/100], Loss: 0.2566\nEpoch [24/100], Loss: 0.0220\nEpoch [24/100], Loss: 0.2643\nEpoch [24/100], Loss: 0.0181\nEpoch [24/100], Loss: 1.3741\nEpoch [25/100], Loss: 0.0310\nEpoch [25/100], Loss: 0.2359\nEpoch [25/100], Loss: 0.1487\nEpoch [25/100], Loss: 0.2353\nEpoch [25/100], Loss: 0.1667\nEpoch [25/100], Loss: 0.1733\nEpoch [25/100], Loss: 0.1764\nEpoch [25/100], Loss: 0.8317\nEpoch [26/100], Loss: 0.3133\nEpoch [26/100], Loss: 0.2559\nEpoch [26/100], Loss: 0.1423\nEpoch [26/100], Loss: 0.1989\nEpoch [26/100], Loss: 0.1924\nEpoch [26/100], Loss: 0.1826\nEpoch [26/100], Loss: 0.2413\nEpoch [26/100], Loss: 0.0863\nEpoch [27/100], Loss: 0.1515\nEpoch [27/100], Loss: 0.3257\nEpoch [27/100], Loss: 0.1409\nEpoch [27/100], Loss: 0.1391\nEpoch [27/100], Loss: 0.0292\nEpoch [27/100], Loss: 0.2584\nEpoch [27/100], Loss: 0.2651\nEpoch [27/100], Loss: 0.0191\nEpoch [28/100], Loss: 0.1435\nEpoch [28/100], Loss: 0.2710\nEpoch [28/100], Loss: 0.1434\nEpoch [28/100], Loss: 0.2660\nEpoch [28/100], Loss: 0.0216\nEpoch [28/100], Loss: 0.2576\nEpoch [28/100], Loss: 0.2531\nEpoch [28/100], Loss: 0.0305\nEpoch [29/100], Loss: 0.2446\nEpoch [29/100], Loss: 0.1396\nEpoch [29/100], Loss: 0.2390\nEpoch [29/100], Loss: 0.1416\nEpoch [29/100], Loss: 0.1429\nEpoch [29/100], Loss: 0.0529\nEpoch [29/100], Loss: 0.3261\nEpoch [29/100], Loss: 0.0547\nEpoch [30/100], Loss: 0.2347\nEpoch [30/100], Loss: 0.0534\nEpoch [30/100], Loss: 0.2355\nEpoch [30/100], Loss: 0.3297\nEpoch [30/100], Loss: 0.0493\nEpoch [30/100], Loss: 0.3308\nEpoch [30/100], Loss: 0.0482\nEpoch [30/100], Loss: 0.0467\nEpoch [31/100], Loss: 0.2382\nEpoch [31/100], Loss: 0.2392\nEpoch [31/100], Loss: 0.1401\nEpoch [31/100], Loss: 0.1398\nEpoch [31/100], Loss: 0.0381\nEpoch [31/100], Loss: 0.2430\nEpoch [31/100], Loss: 0.2439\nEpoch [31/100], Loss: 0.0344\nEpoch [32/100], Loss: 0.1390\nEpoch [32/100], Loss: 0.0321\nEpoch [32/100], Loss: 0.2483\nEpoch [32/100], Loss: 0.1392\nEpoch [32/100], Loss: 0.3602\nEpoch [32/100], Loss: 0.1391\nEpoch [32/100], Loss: 0.2455\nEpoch [32/100], Loss: 0.0357\nEpoch [33/100], Loss: 0.0372\nEpoch [33/100], Loss: 0.4467\nEpoch [33/100], Loss: 0.2396\nEpoch [33/100], Loss: 0.0451\nEpoch [33/100], Loss: 0.4255\nEpoch [33/100], Loss: 0.0533\nEpoch [33/100], Loss: 0.0564\nEpoch [33/100], Loss: 0.0565\nEpoch [34/100], Loss: 0.2347\nEpoch [34/100], Loss: 0.2350\nEpoch [34/100], Loss: 0.2353\nEpoch [34/100], Loss: 0.1432\nEpoch [34/100], Loss: 0.0498\nEpoch [34/100], Loss: 0.1417\nEpoch [34/100], Loss: 0.2382\nEpoch [34/100], Loss: 0.0410\nEpoch [35/100], Loss: 0.3434\nEpoch [35/100], Loss: 0.2419\nEpoch [35/100], Loss: 0.1395\nEpoch [35/100], Loss: 0.1395\nEpoch [35/100], Loss: 0.1396\nEpoch [35/100], Loss: 0.0375\nEpoch [35/100], Loss: 0.2427\nEpoch [35/100], Loss: 0.0353\nEpoch [36/100], Loss: 0.1391\nEpoch [36/100], Loss: 0.1390\nEpoch [36/100], Loss: 0.1391\nEpoch [36/100], Loss: 0.0293\nEpoch [36/100], Loss: 0.4760\nEpoch [36/100], Loss: 0.2494\nEpoch [36/100], Loss: 0.1390\nEpoch [36/100], Loss: 0.0350\nEpoch [37/100], Loss: 0.0363\nEpoch [37/100], Loss: 0.1393\nEpoch [37/100], Loss: 0.3465\nEpoch [37/100], Loss: 0.1395\nEpoch [37/100], Loss: 0.0394\nEpoch [37/100], Loss: 0.1398\nEpoch [37/100], Loss: 0.4423\nEpoch [37/100], Loss: 0.0423\nEpoch [38/100], Loss: 0.3350\nEpoch [38/100], Loss: 0.1419\nEpoch [38/100], Loss: 0.0501\nEpoch [38/100], Loss: 0.2356\nEpoch [38/100], Loss: 0.0511\nEpoch [38/100], Loss: 0.1426\nEpoch [38/100], Loss: 0.2366\nEpoch [38/100], Loss: 0.5556\nEpoch [39/100], Loss: 0.0506\nEpoch [39/100], Loss: 0.3260\nEpoch [39/100], Loss: 0.1455\nEpoch [39/100], Loss: 0.2340\nEpoch [39/100], Loss: 0.2338\nEpoch [39/100], Loss: 0.1492\nEpoch [39/100], Loss: 0.1495\nEpoch [39/100], Loss: 0.0642\nEpoch [40/100], Loss: 0.1469\nEpoch [40/100], Loss: 0.2345\nEpoch [40/100], Loss: 0.2354\nEpoch [40/100], Loss: 0.1423\nEpoch [40/100], Loss: 0.1414\nEpoch [40/100], Loss: 0.2386\nEpoch [40/100], Loss: 0.0403\nEpoch [40/100], Loss: 0.5825\nEpoch [41/100], Loss: 0.4401\nEpoch [41/100], Loss: 0.1416\nEpoch [41/100], Loss: 0.1437\nEpoch [41/100], Loss: 0.1456\nEpoch [41/100], Loss: 0.1471\nEpoch [41/100], Loss: 0.1478\nEpoch [41/100], Loss: 0.1477\nEpoch [41/100], Loss: 0.0600\nEpoch [42/100], Loss: 0.0556\nEpoch [42/100], Loss: 0.0493\nEpoch [42/100], Loss: 0.3372\nEpoch [42/100], Loss: 0.1395\nEpoch [42/100], Loss: 0.2435\nEpoch [42/100], Loss: 0.1391\nEpoch [42/100], Loss: 0.2466\nEpoch [42/100], Loss: 0.6062\nEpoch [43/100], Loss: 0.1394\nEpoch [43/100], Loss: 0.4354\nEpoch [43/100], Loss: 0.4193\nEpoch [43/100], Loss: 0.0650\nEpoch [43/100], Loss: 0.0754\nEpoch [43/100], Loss: 0.0813\nEpoch [43/100], Loss: 0.1590\nEpoch [43/100], Loss: 0.0805\nEpoch [44/100], Loss: 0.1546\nEpoch [44/100], Loss: 0.3169\nEpoch [44/100], Loss: 0.0631\nEpoch [44/100], Loss: 0.3233\nEpoch [44/100], Loss: 0.1437\nEpoch [44/100], Loss: 0.2362\nEpoch [44/100], Loss: 0.0451\nEpoch [44/100], Loss: 0.0407\nEpoch [45/100], Loss: 0.5542\nEpoch [45/100], Loss: 0.1393\nEpoch [45/100], Loss: 0.0360\nEpoch [45/100], Loss: 0.1392\nEpoch [45/100], Loss: 0.2446\nEpoch [45/100], Loss: 0.1390\nEpoch [45/100], Loss: 0.0336\nEpoch [45/100], Loss: 0.0323\nEpoch [46/100], Loss: 0.4660\nEpoch [46/100], Loss: 0.0316\nEpoch [46/100], Loss: 0.3534\nEpoch [46/100], Loss: 0.1392\nEpoch [46/100], Loss: 0.0368\nEpoch [46/100], Loss: 0.1395\nEpoch [46/100], Loss: 0.1396\nEpoch [46/100], Loss: 0.0382\nEpoch [47/100], Loss: 0.2420\nEpoch [47/100], Loss: 0.1394\nEpoch [47/100], Loss: 0.0363\nEpoch [47/100], Loss: 0.2436\nEpoch [47/100], Loss: 0.4538\nEpoch [47/100], Loss: 0.0375\nEpoch [47/100], Loss: 0.1398\nEpoch [47/100], Loss: 0.0403\nEpoch [48/100], Loss: 0.3402\nEpoch [48/100], Loss: 0.3378\nEpoch [48/100], Loss: 0.1413\nEpoch [48/100], Loss: 0.1424\nEpoch [48/100], Loss: 0.2353\nEpoch [48/100], Loss: 0.0538\nEpoch [48/100], Loss: 0.0536\nEpoch [48/100], Loss: 0.0497\nEpoch [49/100], Loss: 0.1407\nEpoch [49/100], Loss: 0.3464\nEpoch [49/100], Loss: 0.0357\nEpoch [49/100], Loss: 0.1390\nEpoch [49/100], Loss: 0.1389\nEpoch [49/100], Loss: 0.1391\nEpoch [49/100], Loss: 0.2507\nEpoch [49/100], Loss: 0.6166\nEpoch [50/100], Loss: 0.0365\nEpoch [50/100], Loss: 0.1404\nEpoch [50/100], Loss: 0.3315\nEpoch [50/100], Loss: 0.0536\nEpoch [50/100], Loss: 0.2342\nEpoch [50/100], Loss: 0.2339\nEpoch [50/100], Loss: 0.2338\nEpoch [50/100], Loss: 0.0670\nEpoch [51/100], Loss: 0.2338\nEpoch [51/100], Loss: 0.1493\nEpoch [51/100], Loss: 0.0610\nEpoch [51/100], Loss: 0.3257\nEpoch [51/100], Loss: 0.0510\nEpoch [51/100], Loss: 0.1412\nEpoch [51/100], Loss: 0.3418\nEpoch [51/100], Loss: 0.0385\nEpoch [52/100], Loss: 0.1393\nEpoch [52/100], Loss: 0.1390\nEpoch [52/100], Loss: 0.2481\nEpoch [52/100], Loss: 0.1391\nEpoch [52/100], Loss: 0.1391\nEpoch [52/100], Loss: 0.0312\nEpoch [52/100], Loss: 0.4679\nEpoch [52/100], Loss: 0.0337\nEpoch [53/100], Loss: 0.1393\nEpoch [53/100], Loss: 0.2415\nEpoch [53/100], Loss: 0.5388\nEpoch [53/100], Loss: 0.1426\nEpoch [53/100], Loss: 0.0579\nEpoch [53/100], Loss: 0.1480\nEpoch [53/100], Loss: 0.0640\nEpoch [53/100], Loss: 0.0619\nEpoch [54/100], Loss: 0.1455\nEpoch [54/100], Loss: 0.3266\nEpoch [54/100], Loss: 0.0496\nEpoch [54/100], Loss: 0.0453\nEpoch [54/100], Loss: 0.2401\nEpoch [54/100], Loss: 0.1392\nEpoch [54/100], Loss: 0.3512\nEpoch [54/100], Loss: 0.0328\nEpoch [55/100], Loss: 0.2467\nEpoch [55/100], Loss: 0.4617\nEpoch [55/100], Loss: 0.0353\nEpoch [55/100], Loss: 0.0375\nEpoch [55/100], Loss: 0.2411\nEpoch [55/100], Loss: 0.0393\nEpoch [55/100], Loss: 0.2404\nEpoch [55/100], Loss: 0.0397\nEpoch [56/100], Loss: 0.2406\nEpoch [56/100], Loss: 0.0389\nEpoch [56/100], Loss: 0.2415\nEpoch [56/100], Loss: 0.1397\nEpoch [56/100], Loss: 0.2418\nEpoch [56/100], Loss: 0.1395\nEpoch [56/100], Loss: 0.2411\nEpoch [56/100], Loss: 0.0394\nEpoch [57/100], Loss: 0.2405\nEpoch [57/100], Loss: 0.2400\nEpoch [57/100], Loss: 0.2390\nEpoch [57/100], Loss: 0.0440\nEpoch [57/100], Loss: 0.1410\nEpoch [57/100], Loss: 0.2376\nEpoch [57/100], Loss: 0.0450\nEpoch [57/100], Loss: 0.5623\nEpoch [58/100], Loss: 0.3302\nEpoch [58/100], Loss: 0.2345\nEpoch [58/100], Loss: 0.2338\nEpoch [58/100], Loss: 0.2338\nEpoch [58/100], Loss: 0.0752\nEpoch [58/100], Loss: 0.0772\nEpoch [58/100], Loss: 0.1547\nEpoch [58/100], Loss: 0.0705\nEpoch [59/100], Loss: 0.4042\nEpoch [59/100], Loss: 0.2339\nEpoch [59/100], Loss: 0.1460\nEpoch [59/100], Loss: 0.0548\nEpoch [59/100], Loss: 0.0495\nEpoch [59/100], Loss: 0.3358\nEpoch [59/100], Loss: 0.0398\nEpoch [59/100], Loss: 0.0354\nEpoch [60/100], Loss: 0.3558\nEpoch [60/100], Loss: 0.4699\nEpoch [60/100], Loss: 0.0309\nEpoch [60/100], Loss: 0.1390\nEpoch [60/100], Loss: 0.1389\nEpoch [60/100], Loss: 0.0329\nEpoch [60/100], Loss: 0.1391\nEpoch [60/100], Loss: 0.0315\nEpoch [61/100], Loss: 0.1391\nEpoch [61/100], Loss: 0.0283\nEpoch [61/100], Loss: 0.1395\nEpoch [61/100], Loss: 0.3708\nEpoch [61/100], Loss: 0.1396\nEpoch [61/100], Loss: 0.1394\nEpoch [61/100], Loss: 0.2510\nEpoch [61/100], Loss: 0.6140\nEpoch [62/100], Loss: 0.1393\nEpoch [62/100], Loss: 0.1413\nEpoch [62/100], Loss: 0.3257\nEpoch [62/100], Loss: 0.2338\nEpoch [62/100], Loss: 0.1534\nEpoch [62/100], Loss: 0.1575\nEpoch [62/100], Loss: 0.1601\nEpoch [62/100], Loss: 0.0853\nEpoch [63/100], Loss: 0.2356\nEpoch [63/100], Loss: 0.1563\nEpoch [63/100], Loss: 0.2342\nEpoch [63/100], Loss: 0.0666\nEpoch [63/100], Loss: 0.2339\nEpoch [63/100], Loss: 0.3261\nEpoch [63/100], Loss: 0.0496\nEpoch [63/100], Loss: 0.0446\nEpoch [64/100], Loss: 0.0388\nEpoch [64/100], Loss: 0.3522\nEpoch [64/100], Loss: 0.1392\nEpoch [64/100], Loss: 0.2509\nEpoch [64/100], Loss: 0.1395\nEpoch [64/100], Loss: 0.1394\nEpoch [64/100], Loss: 0.2530\nEpoch [64/100], Loss: 0.0273\nEpoch [65/100], Loss: 0.0273\nEpoch [65/100], Loss: 0.2527\nEpoch [65/100], Loss: 0.1394\nEpoch [65/100], Loss: 0.4757\nEpoch [65/100], Loss: 0.1390\nEpoch [65/100], Loss: 0.1393\nEpoch [65/100], Loss: 0.1397\nEpoch [65/100], Loss: 0.0421\nEpoch [66/100], Loss: 0.2380\nEpoch [66/100], Loss: 0.1413\nEpoch [66/100], Loss: 0.2367\nEpoch [66/100], Loss: 0.0490\nEpoch [66/100], Loss: 0.0486\nEpoch [66/100], Loss: 0.0463\nEpoch [66/100], Loss: 0.4349\nEpoch [66/100], Loss: 0.5657\nEpoch [67/100], Loss: 0.1420\nEpoch [67/100], Loss: 0.3262\nEpoch [67/100], Loss: 0.1466\nEpoch [67/100], Loss: 0.1489\nEpoch [67/100], Loss: 0.2338\nEpoch [67/100], Loss: 0.2340\nEpoch [67/100], Loss: 0.0723\nEpoch [67/100], Loss: 0.0708\nEpoch [68/100], Loss: 0.1499\nEpoch [68/100], Loss: 0.2339\nEpoch [68/100], Loss: 0.1451\nEpoch [68/100], Loss: 0.3279\nEpoch [68/100], Loss: 0.0483\nEpoch [68/100], Loss: 0.3341\nEpoch [68/100], Loss: 0.0430\nEpoch [68/100], Loss: 0.0401\nEpoch [69/100], Loss: 0.1391\nEpoch [69/100], Loss: 0.1389\nEpoch [69/100], Loss: 0.2489\nEpoch [69/100], Loss: 0.2502\nEpoch [69/100], Loss: 0.1393\nEpoch [69/100], Loss: 0.1391\nEpoch [69/100], Loss: 0.1393\nEpoch [69/100], Loss: 0.6161\nEpoch [70/100], Loss: 0.3486\nEpoch [70/100], Loss: 0.3367\nEpoch [70/100], Loss: 0.1440\nEpoch [70/100], Loss: 0.1484\nEpoch [70/100], Loss: 0.0716\nEpoch [70/100], Loss: 0.0760\nEpoch [70/100], Loss: 0.2347\nEpoch [70/100], Loss: 0.0759\nEpoch [71/100], Loss: 0.0719\nEpoch [71/100], Loss: 0.2338\nEpoch [71/100], Loss: 0.2340\nEpoch [71/100], Loss: 0.2346\nEpoch [71/100], Loss: 0.1432\nEpoch [71/100], Loss: 0.2366\nEpoch [71/100], Loss: 0.1410\nEpoch [71/100], Loss: 0.0417\nEpoch [72/100], Loss: 0.0378\nEpoch [72/100], Loss: 0.0332\nEpoch [72/100], Loss: 0.0284\nEpoch [72/100], Loss: 0.1403\nEpoch [72/100], Loss: 0.3848\nEpoch [72/100], Loss: 0.2653\nEpoch [72/100], Loss: 0.3870\nEpoch [72/100], Loss: 0.6554\nEpoch [73/100], Loss: 0.1391\nEpoch [73/100], Loss: 0.3443\nEpoch [73/100], Loss: 0.0478\nEpoch [73/100], Loss: 0.1456\nEpoch [73/100], Loss: 0.1495\nEpoch [73/100], Loss: 0.3154\nEpoch [73/100], Loss: 0.1568\nEpoch [73/100], Loss: 0.0831\nEpoch [74/100], Loss: 0.1595\nEpoch [74/100], Loss: 0.1581\nEpoch [74/100], Loss: 0.2347\nEpoch [74/100], Loss: 0.2341\nEpoch [74/100], Loss: 0.1507\nEpoch [74/100], Loss: 0.1481\nEpoch [74/100], Loss: 0.1455\nEpoch [74/100], Loss: 0.5427\nEpoch [75/100], Loss: 0.3276\nEpoch [75/100], Loss: 0.1438\nEpoch [75/100], Loss: 0.2348\nEpoch [75/100], Loss: 0.1447\nEpoch [75/100], Loss: 0.2345\nEpoch [75/100], Loss: 0.1449\nEpoch [75/100], Loss: 0.0549\nEpoch [75/100], Loss: 0.0521\nEpoch [76/100], Loss: 0.1420\nEpoch [76/100], Loss: 0.2381\nEpoch [76/100], Loss: 0.3392\nEpoch [76/100], Loss: 0.1399\nEpoch [76/100], Loss: 0.1398\nEpoch [76/100], Loss: 0.1396\nEpoch [76/100], Loss: 0.1394\nEpoch [76/100], Loss: 0.0360\nEpoch [77/100], Loss: 0.1391\nEpoch [77/100], Loss: 0.1391\nEpoch [77/100], Loss: 0.1390\nEpoch [77/100], Loss: 0.0288\nEpoch [77/100], Loss: 0.2523\nEpoch [77/100], Loss: 0.0260\nEpoch [77/100], Loss: 0.6013\nEpoch [77/100], Loss: 0.0273\nEpoch [78/100], Loss: 0.0290\nEpoch [78/100], Loss: 0.2486\nEpoch [78/100], Loss: 0.3542\nEpoch [78/100], Loss: 0.1391\nEpoch [78/100], Loss: 0.1397\nEpoch [78/100], Loss: 0.0421\nEpoch [78/100], Loss: 0.2380\nEpoch [78/100], Loss: 0.5560\nEpoch [79/100], Loss: 0.3262\nEpoch [79/100], Loss: 0.1478\nEpoch [79/100], Loss: 0.0694\nEpoch [79/100], Loss: 0.2343\nEpoch [79/100], Loss: 0.1557\nEpoch [79/100], Loss: 0.3134\nEpoch [79/100], Loss: 0.0793\nEpoch [79/100], Loss: 0.0771\nEpoch [80/100], Loss: 0.0716\nEpoch [80/100], Loss: 0.0637\nEpoch [80/100], Loss: 0.1446\nEpoch [80/100], Loss: 0.1416\nEpoch [80/100], Loss: 0.4427\nEpoch [80/100], Loss: 0.2421\nEpoch [80/100], Loss: 0.2431\nEpoch [80/100], Loss: 0.0349\nEpoch [81/100], Loss: 0.0336\nEpoch [81/100], Loss: 0.2466\nEpoch [81/100], Loss: 0.0303\nEpoch [81/100], Loss: 0.1391\nEpoch [81/100], Loss: 0.1394\nEpoch [81/100], Loss: 0.3673\nEpoch [81/100], Loss: 0.2516\nEpoch [81/100], Loss: 0.6164\nEpoch [82/100], Loss: 0.3464\nEpoch [82/100], Loss: 0.0450\nEpoch [82/100], Loss: 0.2349\nEpoch [82/100], Loss: 0.1475\nEpoch [82/100], Loss: 0.1510\nEpoch [82/100], Loss: 0.0730\nEpoch [82/100], Loss: 0.3145\nEpoch [82/100], Loss: 0.0764\nEpoch [83/100], Loss: 0.1547\nEpoch [83/100], Loss: 0.0716\nEpoch [83/100], Loss: 0.0656\nEpoch [83/100], Loss: 0.3222\nEpoch [83/100], Loss: 0.2349\nEpoch [83/100], Loss: 0.2358\nEpoch [83/100], Loss: 0.1416\nEpoch [83/100], Loss: 0.5610\nEpoch [84/100], Loss: 0.1414\nEpoch [84/100], Loss: 0.3309\nEpoch [84/100], Loss: 0.1430\nEpoch [84/100], Loss: 0.1440\nEpoch [84/100], Loss: 0.2346\nEpoch [84/100], Loss: 0.2345\nEpoch [84/100], Loss: 0.0578\nEpoch [84/100], Loss: 0.0571\nEpoch [85/100], Loss: 0.2347\nEpoch [85/100], Loss: 0.1435\nEpoch [85/100], Loss: 0.1425\nEpoch [85/100], Loss: 0.2368\nEpoch [85/100], Loss: 0.4308\nEpoch [85/100], Loss: 0.0458\nEpoch [85/100], Loss: 0.0454\nEpoch [85/100], Loss: 0.0433\nEpoch [86/100], Loss: 0.2400\nEpoch [86/100], Loss: 0.2410\nEpoch [86/100], Loss: 0.2416\nEpoch [86/100], Loss: 0.1395\nEpoch [86/100], Loss: 0.0371\nEpoch [86/100], Loss: 0.2427\nEpoch [86/100], Loss: 0.1392\nEpoch [86/100], Loss: 0.0353\nEpoch [87/100], Loss: 0.2444\nEpoch [87/100], Loss: 0.0334\nEpoch [87/100], Loss: 0.2457\nEpoch [87/100], Loss: 0.2461\nEpoch [87/100], Loss: 0.1389\nEpoch [87/100], Loss: 0.0334\nEpoch [87/100], Loss: 0.3513\nEpoch [87/100], Loss: 0.0346\nEpoch [88/100], Loss: 0.0349\nEpoch [88/100], Loss: 0.3487\nEpoch [88/100], Loss: 0.1393\nEpoch [88/100], Loss: 0.1394\nEpoch [88/100], Loss: 0.3435\nEpoch [88/100], Loss: 0.1398\nEpoch [88/100], Loss: 0.1405\nEpoch [88/100], Loss: 0.0444\nEpoch [89/100], Loss: 0.0443\nEpoch [89/100], Loss: 0.3363\nEpoch [89/100], Loss: 0.1404\nEpoch [89/100], Loss: 0.2382\nEpoch [89/100], Loss: 0.0439\nEpoch [89/100], Loss: 0.2378\nEpoch [89/100], Loss: 0.0428\nEpoch [89/100], Loss: 1.0972\nEpoch [90/100], Loss: 0.1430\nEpoch [90/100], Loss: 0.2336\nEpoch [90/100], Loss: 0.2340\nEpoch [90/100], Loss: 0.3131\nEpoch [90/100], Loss: 0.0904\nEpoch [90/100], Loss: 0.0954\nEpoch [90/100], Loss: 0.1673\nEpoch [90/100], Loss: 0.4815\nEpoch [91/100], Loss: 0.0936\nEpoch [91/100], Loss: 0.1640\nEpoch [91/100], Loss: 0.0847\nEpoch [91/100], Loss: 0.2347\nEpoch [91/100], Loss: 0.2338\nEpoch [91/100], Loss: 0.1479\nEpoch [91/100], Loss: 0.2345\nEpoch [91/100], Loss: 1.0415\nEpoch [92/100], Loss: 0.1454\nEpoch [92/100], Loss: 0.3195\nEpoch [92/100], Loss: 0.2339\nEpoch [92/100], Loss: 0.3141\nEpoch [92/100], Loss: 0.0825\nEpoch [92/100], Loss: 0.1608\nEpoch [92/100], Loss: 0.0855\nEpoch [92/100], Loss: 0.0818\nEpoch [93/100], Loss: 0.0751\nEpoch [93/100], Loss: 0.1501\nEpoch [93/100], Loss: 0.1459\nEpoch [93/100], Loss: 0.3284\nEpoch [93/100], Loss: 0.1413\nEpoch [93/100], Loss: 0.1401\nEpoch [93/100], Loss: 0.2420\nEpoch [93/100], Loss: 0.5948\nEpoch [94/100], Loss: 0.0360\nEpoch [94/100], Loss: 0.2421\nEpoch [94/100], Loss: 0.2410\nEpoch [94/100], Loss: 0.1400\nEpoch [94/100], Loss: 0.1403\nEpoch [94/100], Loss: 0.0434\nEpoch [94/100], Loss: 0.4334\nEpoch [94/100], Loss: 0.0457\nEpoch [95/100], Loss: 0.1417\nEpoch [95/100], Loss: 0.1418\nEpoch [95/100], Loss: 0.2367\nEpoch [95/100], Loss: 0.1418\nEpoch [95/100], Loss: 0.5218\nEpoch [95/100], Loss: 0.0506\nEpoch [95/100], Loss: 0.0524\nEpoch [95/100], Loss: 0.0521\nEpoch [96/100], Loss: 0.0500\nEpoch [96/100], Loss: 0.1415\nEpoch [96/100], Loss: 0.1406\nEpoch [96/100], Loss: 0.2403\nEpoch [96/100], Loss: 0.1395\nEpoch [96/100], Loss: 0.2432\nEpoch [96/100], Loss: 0.3487\nEpoch [96/100], Loss: 0.0354\nEpoch [97/100], Loss: 0.0353\nEpoch [97/100], Loss: 0.2442\nEpoch [97/100], Loss: 0.0340\nEpoch [97/100], Loss: 0.3515\nEpoch [97/100], Loss: 0.1390\nEpoch [97/100], Loss: 0.3488\nEpoch [97/100], Loss: 0.1394\nEpoch [97/100], Loss: 0.0392\nEpoch [98/100], Loss: 0.2399\nEpoch [98/100], Loss: 0.1403\nEpoch [98/100], Loss: 0.0427\nEpoch [98/100], Loss: 0.1404\nEpoch [98/100], Loss: 0.3376\nEpoch [98/100], Loss: 0.2385\nEpoch [98/100], Loss: 0.1411\nEpoch [98/100], Loss: 0.0457\nEpoch [99/100], Loss: 0.0452\nEpoch [99/100], Loss: 0.1406\nEpoch [99/100], Loss: 0.0411\nEpoch [99/100], Loss: 0.1396\nEpoch [99/100], Loss: 0.2434\nEpoch [99/100], Loss: 0.4560\nEpoch [99/100], Loss: 0.2435\nEpoch [99/100], Loss: 0.0372\nEpoch [100/100], Loss: 0.1396\nEpoch [100/100], Loss: 0.3416\nEpoch [100/100], Loss: 0.0412\nEpoch [100/100], Loss: 0.2388\nEpoch [100/100], Loss: 0.0437\nEpoch [100/100], Loss: 0.2379\nEpoch [100/100], Loss: 0.2377\nEpoch [100/100], Loss: 0.0455\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\nwith torch.no_grad():\n    all_predictions = []\n    all_targets = []\n    for images, targets in test_loader:\n        \n        # Move data to device\n        images = images.to(device)\n        targets = targets.unsqueeze(1).to(device)\n\n        # Forward pass\n        outputs = model(images)\n        predictions = torch.round(outputs)\n\n        # Collect predictions and targets\n        all_predictions.extend(predictions.cpu().numpy().flatten().tolist())\n        all_targets.extend(targets.cpu().numpy().flatten().tolist())\n\n    # Calculate metrics\n    correct = sum(all_predictions[i] == all_targets[i] for i in range(len(all_predictions)))\n    accuracy = correct / len(all_predictions)\n    tp = sum(all_predictions[i] == 1 and all_targets[i] == 1 for i in range(len(all_predictions)))\n    tn = sum(all_predictions[i] == 0 and all_targets[i] == 0 for i in range(len(all_predictions)))\n    fp = sum(all_predictions[i] == 1 and all_targets[i] == 0 for i in range(len(all_predictions)))\n    fn = sum(all_predictions[i] == 0 and all_targets[i] == 1 for i in range(len(all_predictions)))\n    sensitivity = tp / (tp + fn)\n    specificity = tn / (tn + fp)\n    auc = roc_auc_score(all_targets, all_predictions)\n    p_value = ttest_ind(all_predictions, all_targets).pvalue","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:26:44.744543Z","iopub.execute_input":"2023-06-16T11:26:44.744876Z","iopub.status.idle":"2023-06-16T11:26:45.374286Z","shell.execute_reply.started":"2023-06-16T11:26:44.744849Z","shell.execute_reply":"2023-06-16T11:26:45.373325Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_97/1521511933.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n  p_value = ttest_ind(all_predictions, all_targets).pvalue\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"Specificity:\", specificity)\nprint(\"AUC:\", auc)\nprint(\"p-value:\", p_value)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T11:26:45.375542Z","iopub.execute_input":"2023-06-16T11:26:45.377732Z","iopub.status.idle":"2023-06-16T11:26:45.383729Z","shell.execute_reply.started":"2023-06-16T11:26:45.377698Z","shell.execute_reply":"2023-06-16T11:26:45.382815Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Accuracy: 0.20952380952380953\nSensitivity: 1.0\nSpecificity: 0.0\nAUC: 0.5\np-value: 9.060476321175233e-50\n","output_type":"stream"}]}]}